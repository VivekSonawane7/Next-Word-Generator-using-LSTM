{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o33sJT_tlYam"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BRUCv3J8mEGa"
      },
      "outputs": [],
      "source": [
        "\n",
        "df = pd.read_csv(\"qoute_dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iO08KswdmMSo"
      },
      "outputs": [],
      "source": [
        "\n",
        "quotes = df['quote']\n",
        "quotes.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5j6VOLSmMPy"
      },
      "outputs": [],
      "source": [
        "quotes = quotes.str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZQmo6RbmMLC"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "translator = str.maketrans('', '', string.punctuation)\n",
        "quotes = quotes.apply(lambda x: x.translate(translator))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siU3a1cBmMIj"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6-kanvamMGC"
      },
      "outputs": [],
      "source": [
        "vocab_size = 10000\n",
        "\n",
        "tokinizer = Tokenizer(num_words=vocab_size)\n",
        "tokinizer.fit_on_texts(quotes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8EjBGkUmMDk"
      },
      "outputs": [],
      "source": [
        "word_index = tokinizer.word_index\n",
        "print(len(word_index))\n",
        "list(word_index.items())[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUT8JuISmMA4"
      },
      "outputs": [],
      "source": [
        "sequence = tokinizer.texts_to_sequences(quotes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOs2nYgdmL-h"
      },
      "outputs": [],
      "source": [
        "for i in range(3):\n",
        "  print(quotes[i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLW7Ow6GmL5i"
      },
      "outputs": [],
      "source": [
        "for i in range(3):\n",
        "  print(sequence[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyUw7PCHmL3Q"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for seq in sequence:\n",
        "  for i in range(1,len(seq)):\n",
        "    input_seq = seq[:i]\n",
        "    output_seq = seq[i]\n",
        "    X.append(input_seq)\n",
        "    y.append(output_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wm9F4b8EnvRF"
      },
      "outputs": [],
      "source": [
        "max_len = max(len(x) for x in X)\n",
        "print(max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Xe96tabnvOj"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "X_padded = pad_sequences(X, maxlen=max_len, padding='pre')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDqr0y_HnvMB"
      },
      "outputs": [],
      "source": [
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pndnqjbqo8Tj"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y_one_hot = to_categorical(y, num_classes=vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZU5Wj0wBnvHW"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,SimpleRNN,LSTM, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2Jtn64onvFJ"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 50\n",
        "rnn_units = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XV2W_FenvCU"
      },
      "outputs": [],
      "source": [
        "rnn_model = Sequential()\n",
        "\n",
        "rnn_model.add(\n",
        "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len)\n",
        ")\n",
        "rnn_model.add(SimpleRNN(units=rnn_units))\n",
        "rnn_model.add(Dense(units=vocab_size, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqH5Bpl4nu_t"
      },
      "outputs": [],
      "source": [
        "rnn_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHOfZqSknu89"
      },
      "outputs": [],
      "source": [
        "rnn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbPjJD1Gnu6q"
      },
      "outputs": [],
      "source": [
        "lstm_model = Sequential()\n",
        "lstm_model.add(\n",
        "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len)\n",
        ")\n",
        "lstm_model.add(LSTM(units=rnn_units))\n",
        "lstm_model.add(Dense(units=vocab_size, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0-C_hHinu3v"
      },
      "outputs": [],
      "source": [
        "lstm_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnY0wIammL0_"
      },
      "outputs": [],
      "source": [
        "lstm_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A54gfyr6ncik"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open(\"tokenizer.pkl\", \"wb\") as f:\n",
        "  pickle.dump(tokinizer, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnepIBz0mLyj"
      },
      "outputs": [],
      "source": [
        "with open(\"max_len.pkl\", \"wb\") as f:\n",
        "  pickle.dump(max_len, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79283675"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56276d4d"
      },
      "outputs": [],
      "source": [
        "lstm_model.fit(X_padded, y_one_hot, epochs=50, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mw3-35wgmLvQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "lstm_model.save(\"lstm_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3XJaMm-mLqw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGPZ3fwSmLmQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9VrZ5yKmLjw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
